<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner imge, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:imge" content="static/imge/your_banner_imge.png" />
  <meta property="og:imge:width" content="1200"/>
  <meta property="og:imge:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner imge, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:imge" content="static/imges/your_twitter_banner_imge.png">
  <meta name="twitter:card" content="summary_large_imge">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Online Multi-modal Person Search in Videos</title>
  <link rel="icon" type="imge/x-icon" href="/img/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Online Multi-modal Person Search in Videos</h1>
              <div class="is-size-5 publication-authors">
                <a href="https://www.linkedin.com/in/jiangyue-xia-b2055292/">Jiangyue Xia<sup>1</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;
                <a href="https://anyirao.com/">Anyi Rao<sup>2</sup>*</a>&nbsp;&nbsp;&nbsp;&nbsp;
                <a href="https://eveneveno.github.io/lnxu/">Linning Xu<sup>2</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;
                <a href="http://qqhuang.cn/">Qingqiu Huang<sup>1</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;
                <a href="http://www.cs.tsinghua.edu.cn/publish/csen/4623/2010/20101224194147178943406/20101224194147178943406_.html">Jiangtao Wen<sup>1</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;
                <a href="http://dahua.me/">Dahua Lin<sup>1</sup></a>
              </div>

              <div class="is-size-5 publication-authors">
                <a href="http://www.cs.tsinghua.edu.cn/publish/csen/index.html">Tsinghua University<sup>1</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                <a href="http://mmlab.ie.cuhk.edu.hk/">MMLab, The Chinese University of Hong Kong<sup>2</sup></a>
                <span class="eql-cntrb"><br>ECCV 2020</span>
                <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Corresponding Author</small></span>
              </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                    <!-- Arxiv PDF link -->
                    <span class="link-block">
                        <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123570171.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <!-- <span class="link-block">
                    <a href="https://github.com/AnyiRao/SceneSeg" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                  </span> -->

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2008.03546" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                 </a>
                 </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video> -->
      <img src="./img/teaser.jpg" alt="MY ALT TEXT"/>
      <h2 class="content has-text-justified">
        <p>
          The task of searching certain people in videos has seen increasing potential in real-world applications,
          such as video organization and editing. Most existing approaches are devised to work in an offline manner,
          where identifies can only be inferred after an entire video is examined. This working manner precludes such methods from
          being applied to online services or those applications that require real-time responses.
          In this paper, we propose an online person search framework, which can recognize people in a video on the fly.
          This framework maintains a multi-modal memory bank at its heart as the basis for person recognition, and updates it dynamically
          with a policy obtained by reinforcement learning. Our experiments on a large movie dataset show that the proposed method is effective,
          not only achieving remarkable improvements over strong online schemes but also outperforming offline methods.
        </p>
      </h2>
    </div>
  </div>
</section>


<div class="container is-max-desktop">
  <div class="columns is-centered">
    <div class="column has-text-centered">

      <section class="hero is-small">
        <div class="hero-body">
          <div class="container">
            <h2 class="title is-4">Online Multi-modal Searching Machine</h2>
              <div class="content has-text-justified">
                <p>
                Given the portraits of a list of casts, our goal is to search them in a sequential movie with an online fashion following the human behaviors. To tackle this
                challenging problem, we propose a novel online multi-modal searching machine
                (OMS). 
                
                There are four key components in OMS, i.e.
                multimodal feature representations (MFR), a dynamic memory bank (DMB),
                an uncertain instance cache (UIC) and a controller. Each instance, represented by
                multi-modal features, is compared with the exemplars stored in the memory
                bank to judge its identity. The controller then determines whether this instance
                should be used to update memory or put into the uncertain instance cache for
                later comparisons. The memory bank and the uncertain instance cache are dynamically updated over time,
                with a strategy operated by the controller. All
                these components together build an “intelligent machine” to watch a movie and
                gradually recognize the characters like what humans do.
                </p>
              </div>
              <br>
          </div>
        </div>
      </section>
    </div>
    </div>
</div>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{xia2020online,
      title={Online Multi-modal Person Search in Videos},
      author={Xia, Jiangyue and Rao, Anyi and Xu, Linning and Huang, Qingqiu and Wen, Jiangtao and Lin, Dahua},
      booktitle = {The European Conference on Computer Vision (ECCV)}, 
      year={2020}
      }</code></pre>
  </div>
</section>

</body>
</html>
